{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73ca87e",
   "metadata": {},
   "source": [
    "## Dense Layer\n",
    "\n",
    "- 다층 퍼셉트론 신경망에서 사용되는 레이어로 입력과 출력을 모두 연결\n",
    "- 첫번째 인자 : 출력 뉴런의 수\n",
    "- input_dim : 입력 뉴런의 수\n",
    "- activation : 활성화 함수 설정\n",
    "    - lenear :Defualt 값, 입력 뉴런과 가중치로 계산된 결과 값이 그대로 출력 값이 됨\n",
    "    - relu : rectifier 함수로 은닉층에 주로 사용\n",
    "    - sigmoid : 시그모이드 함수로 이진 분류 문제에서 출력 층에 주로 사용\n",
    "    - softmax : 다중 클래스 분류 문제에서 출력 층에 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb16701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1c931df3370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dense\n",
    "Dense(8,input_dim=4,activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc8bc2",
   "metadata": {},
   "source": [
    "## Convolution Layer\n",
    "\n",
    "- 다층 퍼셉트론 신경망과 유사하나 이미지가 가지고 있는 특성이 고려되어 설계된 신경망으로 영상 처리에 주로 사용\n",
    "- 첫번째 인자 : Convolution filter의 수\n",
    "- 두번째 인자 : Convolution filter의 사이즈\n",
    "- padding : 경계 처리 방법 \n",
    "    - valid : 유효한 영역만 출력 => 출력 이미지 사이즈는 입력 이미지 사이즈보다 작음 \n",
    "    - same : 출력 이미지 사이즈가 입력 이미지 사이즈와 동일\n",
    "- input_shape : 샘플 수를 제외한 입력 형태를 정의, 모델에서 첫 레이어일 때만 정의하면 되는데 (행, 열, 채널 수)로 정의  \n",
    "    (이 때 흑백영상일 때 channel이 1이고, 컬러(RGB) 일때는 channel이 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7c6c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1c931df8520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers.convolutional import MaxPooling2D\n",
    "MaxPooling2D(pool_size=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a9d33",
   "metadata": {},
   "source": [
    "## Max Pooling Layer\n",
    "\n",
    "- Convolution Layer의 출력 이미지에서 주요 값만 뽑아 크기가 작은 출력 영상 생성\n",
    "- pool_size : 수직, 수평 축소 비율을 지정. (2,2)라면 출력 영상 크기는 입력 영상 크기의 반으로 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7645df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1c93de43c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
    "Conv2D(32,(5,5), padding='valid',input_shape=(28,28,1),activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86141f28",
   "metadata": {},
   "source": [
    "## Flatten Layer\n",
    "\n",
    "- Convolution Layer나 Max Pooling Layer 를 반복적으로 거치면 주요 특징만 추출되고 추출된 주요 특징은 전결합층에 전달되어 학습\n",
    "- 전결합층에 전달하기 위해 1차원 자료로 바꿔주는데 이때 사용되는 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851c43b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Flatten at 0x1c931df3af0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Flatten \n",
    "Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590478f4",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Layer를 쌓아올려 Model 구성\n",
    "- Conv2D Layer -> MaxPooling2D Layer -> Conv2D Layer -> MaxPooling2D Layer -> Flatten Layer -> Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff1535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling2D\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(2,(3,3),padding='same',activation='relu',input_shape=(8,8,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(3,(2,2),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f9345",
   "metadata": {},
   "source": [
    "## 가시화 코드(에러 발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b136ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m SVG(\u001b[43mmodel_to_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m(prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abbe21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4e2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe4e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5862f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
